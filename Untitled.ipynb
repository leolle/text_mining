{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '../../temp/captcha-tensorflow/captcha/images/1232.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bff5809a96b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20180407\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bff5809a96b0>\u001b[0m in \u001b[0;36mwalk\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mClass_Folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moriginal_Folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOR_Vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# 读取该类别文件夹的所有图片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mCF_Tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClass_Folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCF_Tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 取一张图片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# 取一张图片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '../../temp/captcha-tensorflow/captcha/images/1232.jpg'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import PIL.Image as image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from pylab import mpl\n",
    "mpl.rcParams['font.sans-serif'] = 'NSimSun, Times New Roman'\n",
    " \n",
    "# 加载图片，转成矩阵\n",
    "def load_data(file_path):\n",
    "    f = open(file_path, 'rb')  # 二进制打开\n",
    "    data = []\n",
    "    img = image.open(f)  # 以列表形式返回图片像素值\n",
    "    m, n = img.size  # 图片大小\n",
    "    for i in range(m):\n",
    "        for j in range(n):  # 将每个像素点RGB颜色处理到0-1范围内并存放data\n",
    "            x = img.getpixel((i, j))\n",
    "            data.append([x/256.0])\n",
    "    f.close()\n",
    "    return np.mat(data), m, n  # 以矩阵型式返回data，图片大小\n",
    " \n",
    "def K_means(img_data, row, col):\n",
    "    label = KMeans(n_clusters=2, n_init=40, init='k-means++').fit_predict(img_data)  # 聚成两类\n",
    "    label = label.reshape([row, col])  # 聚类获得每个像素所属的类别\n",
    "    if np.sum(label) >= row * col/2:  #分类相反\n",
    "        label = np.abs(np.ones((row, col)) - label)\n",
    "    pic_k = image.new(\"L\", (row, col))  # 创建一张新的灰度图保存聚类后的结果\n",
    "    for i in range(row):  # 根据所属类别向图片中添加灰度值\n",
    "        for j in range(col):\n",
    "            pic_k.putpixel((i, j), int(256 / (label[i][j] + 1)))\n",
    "    return pic_k\n",
    " \n",
    "# 对K_means聚类分割后的图像进行阈值分割转成二值图像\n",
    "def Thresh_and_blur(img):\n",
    " \n",
    "    (_, thresh) = cv2.threshold(img, 130, 255, cv2.THRESH_BINARY)\n",
    " \n",
    "    return thresh\n",
    " \n",
    "# 用数字形态学先腐蚀掉噪声再进行膨胀（开运算）\n",
    "def image_morphology(thresh):\n",
    "    # 建立一个椭圆核函数\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "    # 执行图像形态学\n",
    "    opened = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    # closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "    #opened = cv2.erode(opened, None, iterations=4)  # 腐蚀4次\n",
    "    #opened = cv2.dilate(opened, None, iterations=4)  # 膨胀4次\n",
    "    return opened\n",
    " \n",
    "def findcnts_and_box_point(opened):\n",
    "    # 这里opencv3返回的是三个参数，源图像、轮廓信息、可选参数\n",
    "    # 轮廓检索模式：cv2.RETR_LIST表示提取所有轮廓并记录在列表\n",
    "    # 轮廓逼近方法：cv2.CHAIN_APPROX_SIMPLE，压缩水平、垂直、对角元素，保留终点坐标，如矩形轮廓用4个角点表示\n",
    "    (_, cnts, _) = cv2.findContours(opened.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "    c = c[1]\n",
    "    # compute the rotated bounding box of the largest contour\n",
    "    rect = cv2.minAreaRect(c)  # 生成最小外接矩形，retval包含中心坐标、矩形宽高和旋转角度\n",
    "    box = np.int0(cv2.boxPoints(rect))  # 得到旋转矩阵四个顶点坐标\n",
    " \n",
    "    return box\n",
    " \n",
    "def drawcnts_and_cut(original_img, box):\n",
    "    # draw a bounding box arounded the detected barcode and display the image\n",
    "    draw_img = cv2.drawContours(original_img.copy(), [box], -1, (0, 0, 255), 3)\n",
    "    # 截取图像\n",
    "    Xs = [i[0] for i in box]\n",
    "    Ys = [i[1] for i in box]\n",
    "    x1 = min(Xs)\n",
    "    x2 = max(Xs)\n",
    "    y1 = min(Ys)\n",
    "    y2 = max(Ys)\n",
    "    y_mid = y1 + math.ceil((y2 - y1)/2)\n",
    "    x_mid = x1 + math.ceil((x2 - x1) / 2)\n",
    " \n",
    "    crop_img = original_img[y_mid-25:y_mid+25, x_mid-25:x_mid+25]  # 裁成50*50目标图像\n",
    " \n",
    "    return draw_img, crop_img\n",
    " \n",
    "original_Folder = '../../temp/captcha-tensorflow/captcha/images'\n",
    "OR_Vector = os.listdir(original_Folder)  # 读取待处理文件夹中所有的文件\n",
    "for k in range(len(OR_Vector)):\n",
    "    # 取一个类别文件夹\n",
    "    # Class_Folder = os.path.join('%s/%s' % (original_Folder, OR_Vector[k]))\n",
    "    # 读取该类别文件夹的所有图片\n",
    "    # CF_Tensor = os.listdir(Class_Folder)\n",
    "    # for p in range(len(CF_Tensor)):  # 取一张图片\n",
    "        # 取一张图片\n",
    "        Image_Path = os.path.join('%s/%s' % (Class_Folder, CF_Tensor[p]))\n",
    "        original_img = cv2.imread(Image_Path)\n",
    "        img_data, row, col = load_data(Image_Path)\n",
    "        pic_k = K_means(img_data, row, col)\n",
    "        pic_k = np.asarray(pic_k)\n",
    "        thresh = Thresh_and_blur(pic_k)\n",
    "        opened = image_morphology(thresh)\n",
    "        box = findcnts_and_box_point(opened)\n",
    "        draw_img, crop_img = drawcnts_and_cut(original_img, box)\n",
    "\n",
    "        # 保存切割后的图片\n",
    "        # Save_Folder = 'F:\\pycharm\\\\test_IO\\\\MSTAR-10_denoise_enl4\\\\train_denoise_enl4_segment'\n",
    "        # SA_Vector = os.listdir(Save_Folder)  # 读取保存的文件夹中所有的文件\n",
    "        # Class_Folder2 = os.path.join('%s\\%s' % (Save_Folder, SA_Vector[k]))\n",
    "        # Save_Path = os.path.join('%s\\%s' % (Class_Folder2, CF_Tensor[p]))\n",
    "        # cv2.imwrite(Save_Path, crop_img)\n",
    "\n",
    "        titles = [u'去噪后图像', u'K-means聚类后', u'二值化处理', u'开运算', u'定位目标区域', u'切割后的图像']\n",
    "        images = [original_img, pic_k, thresh, opened, draw_img, crop_img] #\n",
    "        for i in range(6):\n",
    "            plt.subplot(2, 3, i + 1), plt.imshow(images[i], 'gray')\n",
    "            plt.title(titles[i])\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "        cv2.waitKey(20180407)\n",
    "\n",
    "# walk()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'tuple' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-48131c82372f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mImage_Path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../temp/captcha-tensorflow/captcha/images/1232.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moriginal_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage_Path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage_Path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpic_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpic_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bff5809a96b0>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 将每个像素点RGB颜色处理到0-1范围内并存放data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpixel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m256.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m  \u001b[0;31m# 以矩阵型式返回data，图片大小\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'tuple' and 'float'"
     ]
    }
   ],
   "source": [
    "Image_Path = '../../temp/captcha-tensorflow/captcha/images/1232.jpg'\n",
    "original_img = cv2.imread(Image_Path)\n",
    "img_data, row, col = load_data(Image_Path)\n",
    "pic_k = K_means(img_data, row, col)\n",
    "pic_k = np.asarray(pic_k)\n",
    "thresh = Thresh_and_blur(pic_k)\n",
    "opened = image_morphology(thresh)\n",
    "box = findcnts_and_box_point(opened)\n",
    "draw_img, crop_img = drawcnts_and_cut(original_img, box)\n",
    "\n",
    "# 保存切割后的图片\n",
    "# Save_Folder = 'F:\\pycharm\\\\test_IO\\\\MSTAR-10_denoise_enl4\\\\train_denoise_enl4_segment'\n",
    "# SA_Vector = os.listdir(Save_Folder)  # 读取保存的文件夹中所有的文件\n",
    "# Class_Folder2 = os.path.join('%s\\%s' % (Save_Folder, SA_Vector[k]))\n",
    "# Save_Path = os.path.join('%s\\%s' % (Class_Folder2, CF_Tensor[p]))\n",
    "# cv2.imwrite(Save_Path, crop_img)\n",
    "\n",
    "titles = [u'去噪后图像', u'K-means聚类后', u'二值化处理', u'开运算', u'定位目标区域', u'切割后的图像']\n",
    "images = [original_img, pic_k, thresh, opened, draw_img, crop_img] #\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "cv2.waitKey(20180407)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the image and compute the ratio of the old height\n",
    "# to the new height, clone it, and resize it\n",
    "image = cv2.imread(args[\"image\"])\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)\n",
    "\n",
    "# convert the image to grayscale, blur it, and find edges\n",
    "# in the image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "# show the original image and the edge detected image\n",
    "print \"STEP 1: Edge Detection\"\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "(cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "\t# approximate the contour\n",
    "\tperi = cv2.arcLength(c, True)\n",
    "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "\t# if our approximated contour has four points, then we\n",
    "\t# can assume that we have found our screen\n",
    "\tif len(approx) == 4:\n",
    "\t\tscreenCnt = approx\n",
    "\t\tbreak\n",
    "\n",
    "# show the contour (outline) of the piece of paper\n",
    "print \"STEP 2: Find contours of paper\"\n",
    "cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# apply the four point transform to obtain a top-down\n",
    "# view of the original image\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "# convert the warped image to grayscale, then threshold it\n",
    "# to give it that 'black and white' paper effect\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "warped = threshold_adaptive(warped, 250, offset = 10)\n",
    "warped = warped.astype(\"uint8\") * 255\n",
    "\n",
    "# show the original and scanned images\n",
    "print \"STEP 3: Apply perspective transform\"\n",
    "cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Save transformed image\n",
    "sp = args['image'].split('.')\n",
    "save_filename = sp[0] + '_' + args['scanned'] + '.' + sp[1]\n",
    "cv2.imwrite(save_filename, warped)\n",
    "\n",
    "###\n",
    "#Convert image to csv fie\n",
    "###\n",
    "\n",
    "# show the original and scanned images\n",
    "print \"STEP 4: Convert receipt to csv file\"\n",
    "csv_filename = sp[0] + '.csv'\n",
    "csv_file = open(csv_filename, \"w\")\n",
    "\n",
    "if(args['which_receipt'] == 'winco'):\n",
    "    process_line = winco_receipt_line\n",
    "\n",
    "st = pytesseract.image_to_string(Image.open(save_filename), config=\"-psm 6\")\n",
    "for cur_line in st.split('\\n'):\n",
    "    print(cur_line)\n",
    "    ret = process_line(cur_line)\n",
    "\n",
    "    if(ret is None):\n",
    "        continue\n",
    "\n",
    "    csv_file.write(ret + '\\n')\n",
    "\n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
